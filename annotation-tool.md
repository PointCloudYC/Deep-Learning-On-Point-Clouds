## annotation tools

- [CloudCompare](http://cloudcompare.net/)(CC) (opensource, high capability, fast)
- [Autodesk Recap](https://www.autodesk.com/products/recap/overview) (student-free, medium capability, slow)
- [Hitachi semantic-segmentation-editor](https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor)(SSE) (opensource, flexible)
- [Latte](https://github.com/bernwang/latte), mainly for detection (University of California, Berkeley)
- [supervise.ly](supervise.ly) ( web open source )
- [Playment.io](Playment.io) (Commercial, only detection task)
- PCL-based annotation tools: [point-cloud-annotation-tool](https://github.com/springzfx/point-cloud-annotation-tool), and [cloud_annotation_tool](https://github.com/yzrobot/cloud_annotation_tool) (opensource, based on PCL)

## suggested tools

Considering efficiency, flexibility and open source or not, Cloudcompare and semantic-segmentation-editor are 2 candidate annotation tools for our labeling work.

- Hitachi semantic-segmentation-editor(SSE)
- CloudCompare
